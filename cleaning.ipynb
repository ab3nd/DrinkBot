{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spidering and data handling is in spiderlings.ipynb, this one is for cleaning up the data and normalzing the JSON format. \n",
    "\n",
    "The reason I put this all in a notebook is that I expect a lot of the stuff to vary wildly from file to file. There are a couple of reasons for this. One is that I didn't do a good job of keeping it clean when I was developing the spiders over the course of multiple years of development. The other reason is that the datasets themselves admitted different levels of parsing. \n",
    "\n",
    "For a first pass, I want to clean up ingredients. I'm going to want to normalize a couple of different aspects of the representation:\n",
    "\n",
    "- All liquids in the same units\n",
    "    - Might be centiliters\n",
    "    - dashes, barspoons, etc. need conversion\n",
    "- All names of cocktails in title case (Gin Martini, not GIN MARTINI)\n",
    "- Cocktials with matching names assigned a unique ID as well (Martini-01, etc.)\n",
    "- Ingredients normalized so largest amount is 1, others proportional to that\n",
    "    - Not so they sum to one, that loses relative scale\n",
    "- Some way of handling garnishes and muddled ingredients\n",
    "    - Eggs, muddled ingredients tend to get counted rather than measured. \n",
    "- Language modeling to normalize instructions\n",
    "\n",
    "For no reason other than that I picked it at random, I'm going for the Martha Stewart data first. The file is, unfortunately, not well-formatted JSON, because I created it... fuuuuck. 4 years ago. Time flies. \n",
    "\n",
    "Anyway, issue one is that the data is, for each line in the file, a JSON dictionary of the form:\n",
    "\n",
    "```json\n",
    "{\"name\": \"Strawberry-Cucumber Gin-Elderflower Spritz\", \"ingredients\": [\"12 strawberries, hulled and sliced (1 1/4 cups), plus whole berries for serving\", \"12 thin cucumber slices, halved (3/4 cup), plus whole rounds for serving\", \"2 tablespoons superfine sugar\", \"3 ounces fresh lemon juice\", \"9 ounces gin, such as Citadelle, chilled\", \"6 ounces St-Germain, chilled\", \"Club soda, chilled; and Peychaud's bitters, for serving\"], \"instructions\": [\"Muddle sliced strawberries, halved cucumber slices, sugar, and lemon juice in the bottom of a pitcher until fruits break down and release most of their juices and sugar has dissolved. Stir in gin and St-Germain to combine. Fill 6 glasses halfway with ice. Divide fruit-and-gin mixture evenly among glasses. Top each with 1 to 2 ounces club soda; stir once. Top each with a few dashes of bitters, whole strawberries, and cucumber rounds; serve immediately.\"]}\n",
    "```\n",
    "\n",
    "What I actually want is a list of these dicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "recipes = []\n",
    "with open(\"./spiders/data/martha_stewart.json\", 'r') as infile:\n",
    "    for line in infile:\n",
    "        data = json.loads(line)\n",
    "        recipes.append(data)\n",
    "\n",
    "with open(\"./spiders/data/martha_stewart_cleaned.json\", 'w') as outfile:\n",
    "    json.dump(recipes, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, that's way cleaner. Now the drinks are in a proper list, and the ingredients are, frankly, looking like parsing them is AGI-complete. \n",
    "\n",
    "```json\n",
    "    {\n",
    "        \"name\": \"Sour-Cherry Mojitos\",\n",
    "        \"ingredients\": [\n",
    "            \"1 1/4 cups sugar\",\n",
    "            \"2/3 cup fresh lemon juice (from about 3 lemons)\",\n",
    "            \"3 pounds frozen pitted sour cherries, partially thawed with juices\",\n",
    "            \"1 cup fresh basil leaves, plus more for serving\",\n",
    "            \"2 to 3 cups vodka\",\n",
    "            \"6 cups sparkling water\"\n",
    "        ],\n",
    "        \"instructions\": [\n",
    "            \"Bring sugar and 1 1/4 cups water to a boil in a small saucepan, stirring until sugar is dissolved, 3 minutes. Remove from heat; let cool 15 minutes. Syrup can be refrigerated for up to 1 month.\",\n",
    "            \"Combine lemon juice, fruit, and basil in a bowl. Add syrup; mash lightly to release juices. Refrigerate at least 1 day and up to 4 days.\",\n",
    "            \"Combine fruit mixture and vodka in a pitcher or punch bowl; ladle about 1/3 cup into each glass. Fill with ice. Top with sparkling water, garnish with more basil, and serve.\"\n",
    "        ]\n",
    "    },\n",
    "```\n",
    "\n",
    "That one isn't bad, in the sense that everything is, more or less, a number, a unit, and an ingredient. However, some of them have stuff like \"Club soda, chilled; and Peychaud's bitters, for serving\", which is actually two ingredients and no amounts. There's also \"Licorice Ice Cubes\", which is not further explained. Some of the ingredients also have a link, the link text is usually the ingredient name, although there's also stuff like \"Simple Syrup for Whiskey Sours\". \n",
    "\n",
    "So let's do something simple: for every ingredient that starts with a number, count what the next token is, and graph that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ams/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 79 things that could be ingredients\n",
      "[['ounce', 554], ['cup', 529], ['tablespoon', 171], ['teaspoon', 129], ['lime', 30], ['bottle', 28], ['dash', 19], ['thin', 14], ['cinnamon', 13], ['pound', 12], ['small', 12], ['large', 11], ['can', 11], ['orange', 10], ['sprig', 9], ['whole', 8], ['strip', 8], ['lemon', 7], ['cucumber', 6], ['pint', 6], ['blackberry', 5], ['fresh', 5], ['750-ml', 5], ['strawberry', 4], ['quart', 4], ['mint', 4], ['bunch', 4], ['organic', 4], ['black', 4], ['slice', 4], ['rosemary', 4], ['glass', 3], ['vanilla', 3], ['maraschino', 3], ['to', 3], ['sliced', 3], ['sugar', 3], ['medium', 3], ['serrano', 3], ['basil', 3], ['(2', 3], ['ruby-red', 2], ['egg', 2], ['edible', 2], ['plum', 2], ['thyme', 2], ['piece', 2], ['cherry', 2], ['stalk', 2], ['ripe', 2], ['canned', 2], ['star-anise', 1], ['pimento-stuffed', 1], ['1/4-inch-thick', 1], ['mango', 1], ['jalapeno', 1], ['inch', 1], ['thick', 1], ['quarter-inch-thick', 1], ['one-inch', 1], ['packet', 1], ['hibiscus', 1], ['raspberry', 1], ['habanero', 1], ['teabags', 1], ['12-ounce', 1], ['mini-cucumber', 1], ['cardamom', 1], ['(250', 1], ['750ml-bottle', 1], ['cilantro', 1], ['brandied', 1], ['jar', 1], ['peach', 1], ['nectarine', 1], ['apricot', 1], ['jarred', 1], ['English', 1], ['navel', 1]]\n",
      "Didn't handle 427 of 2139 ingredients (19.963%)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "counts = {}\n",
    "total = 0\n",
    "unhandled = 0\n",
    "\n",
    "#ps = PorterStemmer()\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "def update(d, k):\n",
    "    # No more toy stemmer\n",
    "    k = k.strip(',')\n",
    "    k = lemma.lemmatize(k)\n",
    "    if k in d.keys():\n",
    "        d[k] += 1\n",
    "    else:\n",
    "        d[k] = 1\n",
    "\n",
    "try:\n",
    "    for recipe in recipes:\n",
    "        for ing in recipe['ingredients']:\n",
    "            total += 1\n",
    "            if re.match(\"[1-9] [1-9]/[1-9]\", ing):\n",
    "                # Number followed by a fraction\n",
    "                tokens = ing.split()\n",
    "                update(counts, tokens[2])\n",
    "            elif re.match(\"[1-9]/[1-9] to [1-9] [1-9]/[1-9]\", ing):\n",
    "                # Fraction followed by a fraction\n",
    "                tokens = ing.split()\n",
    "                update(counts, tokens[4])\n",
    "            elif re.match(\"[1-9] to [1-9]\", ing):\n",
    "                # Variable amount\n",
    "                tokens = ing.split()\n",
    "                update(counts, tokens[3])\n",
    "            elif re.match(\"[1-9]\", ing):\n",
    "                tokens = ing.split()\n",
    "                update(counts, tokens[1])\n",
    "            else:\n",
    "                unhandled += 1\n",
    "except IndexError as e:\n",
    "    print(e)\n",
    "    print(ing)\n",
    "\n",
    "# Prettyprint the counts\n",
    "print(f\"There are {len(counts.keys())} things that could be ingredients\") \n",
    "print(sorted([[k, v] for k, v in counts.items()], key = lambda x: x[1], reverse=True))\n",
    "print(f\"Didn't handle {unhandled} of {total} ingredients ({unhandled/total * 100:.3f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatizing the (suspected) amounts gets very clean results. Stemming was doing stuff like \"bottl\" and \"ounc\". Variations of \"cup\" and \"ounce\" account for fully half of the ingredients (1070-some out of 2139), and the basic handler I wrote handles a hair over 80% of the items.  \n",
    "\n",
    "Of the 79 things that could be units, the ones that actually are are\n",
    "\n",
    "```python\n",
    "dict_keys(['tablespoon', 'ounce', 'cup', 'pound', 'teaspoon', 'quart', 'dash', 'glass', 'can', 'bottle', 'pint', 'jar'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = ['tablespoon', 'ounce', 'cup', 'pound', 'teaspoon', 'quart', 'dash', 'can', 'bottle', 'pint', 'jar']\n",
    "\n",
    "# Have to rebuild the data structure, since we can't mutate the lists as we edit them\n",
    "cleaned = []\n",
    "\n",
    "for recipe in recipes:\n",
    "    # Copy name and instructions over\n",
    "    clean_recipe = {\"name\": recipe[\"name\"], \"instructions\": recipe[\"instructions\"], \"ingredients\": []}\n",
    "\n",
    "    for ing in recipe['ingredients']:\n",
    "        # Split and then find the first unit\n",
    "        tokens = ing.split()\n",
    "        replaced = False\n",
    "        tmp_ingred = {}\n",
    "        for t in tokens:\n",
    "            t_clean = t.strip(',')\n",
    "            t_clean = lemma.lemmatize(t)\n",
    "            if t_clean in units:\n",
    "                unit_idx = tokens.index(t)\n",
    "                tmp_ingred[\"ingred_amount\"] = \" \".join(tokens[:unit_idx])\n",
    "                tmp_ingred[\"ingred_unit\"] = t_clean\n",
    "                tmp_ingred[\"ingred_name\"] = \" \".join(tokens[unit_idx+1:])\n",
    "                replaced = True\n",
    "                break\n",
    "        if replaced:\n",
    "            clean_recipe[\"ingredients\"].append(tmp_ingred)\n",
    "        else:\n",
    "            clean_recipe[\"ingredients\"].append(ing)\n",
    "        replaced = False\n",
    "            \n",
    "    cleaned.append(clean_recipe)\n",
    "\n",
    "with open(\"./spiders/data/martha_stewart_cleaned.json\", 'w') as outfile:\n",
    "    json.dump(cleaned, outfile, indent=4)             "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
